# -*- coding: utf-8 -*-
"""Keyword extraction with ALBERT

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PwUGHlCSE6ufD0b_9_cUodesXwHUiroa

#Extracting keywords for tagging of blog post
"""

!pip install beautifulsoup4

import requests

url = "https://pinchofyum.com/black-pepper-stir-fried-udon"
res = requests.get(url)
html_page = res.content

from bs4 import BeautifulSoup

soup = BeautifulSoup(html_page, 'html.parser')
text = soup.find_all(text=True)

set([t.parent.name for t in text])

req=['h1','h2','h3','h4','p']
Text=""
for t in text:
  if t.parent.name in req:
    Text+=t

# Text = """He’s a very loud and charismatic New Yorker who gained internet fame as the crazy and 
# outgoing host of Wine Library TV, a video blog that obsessively talked about everything related to wine. 
# Through online video blogging, he built his wine business from a $3-million-dollar-a-year wine retail 
# store to a $60 million dollar wine wholesale business.Gary Vaynerchuk has built a multi-million dollar 
# empire relating to his personal brand. He’s a two-time best-selling author and co-founder of Vayner Media, 
# a very large digital marketing agency that works with some of the largest brands in the world.He’s been 
# featured in The Wall Street Journal, GQ, and Time Magazine, as well as appeared on Late Night with Conan O’Brien 
# and The Ellen DeGeneres Show."""

Text=' '.join(Text.split()[:200])

Text

"""### step 1: candidate selection from text (blog post)

#### Dealing with unigram and bigrams candidate tokens only 
"""

stop_words = "english"

from sklearn.feature_extraction.text import CountVectorizer

vector=CountVectorizer(ngram_range=(1,2), stop_words=stop_words).fit([Text])

all_candidate_tokens=vector.get_feature_names()

"""#Candidate tokens are generated.
<h2>Now we have to keep important candidate tokens only.</h2>

<p>Candidate token selection using POS tagging, as we know that tags will be important words of the context.therefore it will probably be a noun.so we opt for POS tagging using spacy to eliminate tokens except ( POS: Noun)</p>
"""

import spacy

nlp=spacy.load('en_core_web_sm')
doc=nlp(Text)

nouns = set()
for token in doc:
    if token.pos_ == "NOUN":
        nouns.add(token.text)

nouns

noun_phrases = set(chunk.text.strip().lower() for chunk in doc.noun_chunks)
noun_phrases

all_noun_candidate_tokens=nouns.union(noun_phrases)
all_noun_candidate_tokens

new_candidate_tokens=list(filter(lambda candidate_tokens : candidate_tokens in all_noun_candidate_tokens, all_candidate_tokens))

new_candidate_tokens

"""### Now let's create embeddings for text(blog post) and all filtered imp candidate tokens 

<p>we use autoclass of the hugging face to call ALBERT model for creating embeddings</p>
"""

!pip install transformers

from transformers import TFAutoModel,AutoTokenizer

model=TFAutoModel.from_pretrained('albert-base-v2')
tokenizer=AutoTokenizer.from_pretrained('albert-base-v2')

new_candidate_tokens,len(new_candidate_tokens)

import tensorflow as tf
tokenizer.encode("Hello, my dog is cute", add_special_tokens=True)

candidate_token_embeddings={}
for token in new_candidate_tokens:
  token_id=tf.constant(tokenizer.encode(token,add_special_tokens=True))[None, :]
  candidate_token_embeddings[token]=model(token_id)['pooler_output'][0]

import numpy

len(candidate_token_embeddings)

candidate_token_embeddings.values()

text_tokens=tokenizer(Text,padding=True,return_tensors="tf")
blog_text_embedding=model(text_tokens['input_ids'])['pooler_output']

text_tokens

blog_text_embedding.shape

np.array(blog_text_embedding).shape

"""### Now using candidate embeddings and blog text embeddings we will use similarity measuring metric cosine similarity from sklearn package to decide which tokens are best matched to the blog text"""

from sklearn.metrics.pairwise import cosine_similarity

top_k_tags=[]
score={}
for token,token_embed in candidate_token_embeddings.items():
  score[token]=cosine_similarity(np.array(token_embed).reshape(1,-1),np.array(blog_text_embedding))[0][0]  #compared to blog_text

score

k_tag_score=sorted(score)
k_tag_score[-10:-1]

